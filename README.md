
# Loki Semantic Layer

This project demonstrates a simple, yet powerful logging system using Grafana Loki with a FastAPI backend. The setup revolves around capturing logs generated by a sample application (`flog`) and querying them through a custom FastAPI service, which translates natural language queries into Loki's LogQL. The architecture encompasses Loki for log storage, MinIO for object storage, Grafana for visualization, and an Nginx gateway for routing requests efficiently. The deployment is orchestrated using Docker Compose, showcasing a cohesive microservices environment.

## Prerequisites

- Docker and Docker Compose installed
- Basic understanding of Docker, FastAPI, and logging mechanisms

## Installation Steps

1. **Clone the Repository**

   First, clone this repository to your local system. This contains all required configuration files.

2. **Start the Environment**

   Navigate to the project's root directory, where the `docker-compose.yaml` file is located. Use Docker Compose to build and start all the necessary services:

   ```bash
   docker-compose up -d
   ```

   This command will download the necessary Docker images and start the containers in the background.

3. **Access the Services**

   Once all containers are up and running, you can access the services:

   - **Grafana**: Open your browser and go to `http://localhost:3000/`. Grafana is already configured with Loki as a datasource, and you can start creating dashboards to visualize logs.
   - **FastAPI**: The FastAPI app is running and can accept POST requests on `http://localhost:8000/query` to perform log queries using natural language.

4. **Verify the Operation**

   Ensure all the components are running correctly:

   - Check the logs of each container for any startup errors.
   - In Grafana, ensure you can query logs from Loki (Datasource -> Explore -> Loki).

## Querying Logs with FastAPI

The FastAPI application is designed to receive natural language queries via POST requests and translate them into LogQL queries that are then sent to Loki. The translation mapping is demonstrated with a few dummy examples in the code.

- **Endpoint**: `/query`
- **Method**: `POST`
- **Content-Type**: `application/json`
- **Body**:
  ```json
  {
    "query": "show me all errors"
  }
  ```

For testing, you can use tools like `curl` or Postman:

```bash
curl -X 'POST' \
  'http://localhost:8000/query' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{"query":"show me all errors"}'
```

## Customizing Queries

To customize the natural language to LogQL translation, modify the `natural_language_to_logql` function within the FastAPI application (`main.py`). This requires an understanding of LogQL and potentially more sophisticated NLP techniques for complex queries.

## Logging Configuration

The logging configuration for the sample application (`flog`) and how logs are collected, processed, and stored via Loki is defined in the `alloy-local-config.yaml` and `loki-config.yaml`. These configurations establish the logging pipeline, including relabeling and discovery mechanisms.

## Architectural Overview

- **Loki**: Central log aggregation system, using MinIO for storage.
- **MinIO**: Object storage for logs, mimicking S3 storage locally.
- **Grafana**: Visualization tool for querying and visualizing logs stored in Loki.
- **Nginx Gateway**: Routes queries to the appropriate Loki components (`read`, `write`, etc.).
- **FastAPI**: Python application translating natural language queries into LogQL.
- **`flog`**: Log generator simulating application logs in JSON format.

## Maintenance and Operations

- **Monitoring and Alerts**: Integrate with Grafana Alerting to monitor the health and performance of your logging infrastructure.
- **Data Retention**: Configure Loki and MinIO retention policies based on storage capacity and compliance requirements.
- **Scaling**: Depending on the log volume, consider scaling Loki and MinIO horizontally for improved performance and redundancy.

## Extensions and Utilities

In addition to the core functionality provided by the logging system, `logcli` is a command-line tool that interacts directly with Loki, providing a way to query and tail logs without the need for a web interface like Grafana. `logcli` offers powerful capabilities for developers and operators who prefer working within terminal environments or require scriptable access to log data.

### Installing `logcli`

`logcli` is part of the Grafana Loki project, and its installation is straightforward:

1. Visit the [Loki releases page](https://github.com/grafana/loki/releases) on GitHub.
2. Select the appropriate version of `logcli` for your operating system and architecture.
3. Download the binary and make it executable.

For example, on a Unix-like system, you might use:

```bash
curl -O -L "https://github.com/grafana/loki/releases/download/v3.0.0/logcli-linux-amd64.zip"
unzip logcli-linux-amd64.zip
chmod +x logcli-linux-amd64
mv logcli-linux-amd64 /usr/local/bin/logcli
```

### Running `logcli`

To run `logcli`, you need the address of your Loki server and optionally an OrgID if you are using multi-tenancy. The basic syntax for querying logs with `logcli` is:

```bash
logcli --addr=http://localhost:3100 query "{container=\"run_loki-flog-1\"}"
```

Replace `http://localhost:3100` with the appropriate Loki server address in your setup.

### Note on OrgID

> When working with a multi-tenant Loki setup, you must specify the OrgID for queries, including when using `logcli`. The lack of or an incorrect OrgID will result in no data being returned or an authorization error. Depending on how you've configured Loki and your infrastructure (such as the provided Nginx gateway), this might require including an HTTP header (`X-Scope-OrgID`) in your requests. For `logcli`, this can be achieved with the `--org-id` flag:
>
> ```bash
> logcli --addr=http://localhost:3100 --org-id=tenant1 query "{container=\"run_loki-flog-1\"}"
> ```
>
> Adjust the `--org-id` value according to your specific tenant configuration.
